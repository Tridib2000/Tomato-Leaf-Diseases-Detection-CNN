{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1105687,"sourceType":"datasetVersion","datasetId":619181}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://www.kaggle.com/code/tridibraj/tomato-leaf-diseases-detection-cnn-95?scriptVersionId=184181253\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-06-18T13:27:33.344255Z","iopub.execute_input":"2024-06-18T13:27:33.34476Z","iopub.status.idle":"2024-06-18T13:27:33.361458Z","shell.execute_reply.started":"2024-06-18T13:27:33.344716Z","shell.execute_reply":"2024-06-18T13:27:33.360094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Image parameters","metadata":{}},{"cell_type":"code","source":"\nimg_height, img_width = 256, 256  # Maintain original resolution\nbatch_size = 32\nnum_classes = 10","metadata":{"execution":{"iopub.status.busy":"2024-06-18T13:27:33.364051Z","iopub.execute_input":"2024-06-18T13:27:33.364485Z","iopub.status.idle":"2024-06-18T13:27:33.370766Z","shell.execute_reply.started":"2024-06-18T13:27:33.36445Z","shell.execute_reply":"2024-06-18T13:27:33.369591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Paths to dataset","metadata":{}},{"cell_type":"code","source":"train_dir = '/kaggle/input/tomatoleaf/tomato/train'\nval_dir = '/kaggle/input/tomatoleaf/tomato/val'","metadata":{"execution":{"iopub.status.busy":"2024-06-18T13:27:33.372672Z","iopub.execute_input":"2024-06-18T13:27:33.373214Z","iopub.status.idle":"2024-06-18T13:27:33.385153Z","shell.execute_reply.started":"2024-06-18T13:27:33.373156Z","shell.execute_reply":"2024-06-18T13:27:33.383696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load and preprocess","metadata":{}},{"cell_type":"code","source":"# Efficient Data Loading\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\ndef preprocess(image, label):\n    image = tf.image.resize(image, [img_height, img_width])\n    image = image / 255.0  # Normalize to [0, 1]\n    return image, label\n\n#training dataset\ntrain_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n    train_dir,\n    batch_size=batch_size,\n    image_size=(img_height, img_width),\n    label_mode='categorical'  # Use categorical labels\n).map(preprocess).cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n\n#validation dataset\nval_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n    val_dir,\n    batch_size=batch_size,\n    image_size=(img_height, img_width),\n    label_mode='categorical'  # Use categorical labels\n).map(preprocess).cache().prefetch(buffer_size=AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T13:27:33.387999Z","iopub.execute_input":"2024-06-18T13:27:33.388471Z","iopub.status.idle":"2024-06-18T13:27:39.312746Z","shell.execute_reply.started":"2024-06-18T13:27:33.388428Z","shell.execute_reply":"2024-06-18T13:27:39.311536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Architecture","metadata":{}},{"cell_type":"code","source":"model = Sequential([\n    Conv2D(16, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n    MaxPooling2D((2, 2)),\n\n    Conv2D(32, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n\n    GlobalAveragePooling2D(),\n\n    Dense(128, activation='relu'),\n    Dense(num_classes, activation='softmax')\n])\n\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-06-18T13:27:39.314737Z","iopub.execute_input":"2024-06-18T13:27:39.315235Z","iopub.status.idle":"2024-06-18T13:27:39.449258Z","shell.execute_reply.started":"2024-06-18T13:27:39.315187Z","shell.execute_reply":"2024-06-18T13:27:39.447967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train the Model","metadata":{}},{"cell_type":"code","source":"# Callbacks\ncallbacks = [\n    EarlyStopping(patience=10, verbose=1, restore_best_weights=True),\n    ModelCheckpoint('best_model.keras', save_best_only=True, verbose=1)\n]\n\n\nhistory = model.fit(\n    train_dataset,\n    epochs=50,\n    validation_data=val_dataset,\n    callbacks=callbacks\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T13:27:39.450656Z","iopub.execute_input":"2024-06-18T13:27:39.451025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate the Model & Save","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport itertools\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\n# Assuming history is your training history object\n# Plot training history\nplt.figure(figsize=(12, 4))\n\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.title('Training and Validation Accuracy')\nplt.savefig('/kaggle/working/training_validation_accuracy.png')  # Save the accuracy plot\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.title('Training and Validation Loss')\nplt.savefig('/kaggle/working/training_validation_loss.png')  # Save the loss plot\n\nplt.show()\n\n# Confusion Matrix\nval_labels = []\nval_preds = []\n\nfor images, labels in val_dataset:\n    val_labels.extend(np.argmax(labels.numpy(), axis=1))\n    val_preds.extend(np.argmax(model.predict(images), axis=1))\n\nconf_matrix = confusion_matrix(val_labels, val_preds)\n\n# Plot Confusion Matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap='Blues')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix')\nplt.savefig('/kaggle/working/confusion_matrix.png')  # Save the confusion matrix plot\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T18:33:02.957725Z","iopub.execute_input":"2024-06-18T18:33:02.959248Z","iopub.status.idle":"2024-06-18T18:33:17.365492Z","shell.execute_reply.started":"2024-06-18T18:33:02.959187Z","shell.execute_reply":"2024-06-18T18:33:17.364342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom sklearn.metrics import f1_score, precision_score, recall_score\n\n# Evaluate on validation dataset\nval_loss, val_acc = model.evaluate(val_dataset)\nprint(f\"Validation accuracy: {val_acc:.2f}\")\n\n# Get the true labels and predictions\nval_labels = []\nval_predictions = []\n\nfor images, labels in val_dataset:\n    preds = model.predict(images)\n    val_predictions.extend(np.argmax(preds, axis=1))\n    val_labels.extend(np.argmax(labels.numpy(), axis=1))\n\n# Compute precision, recall, and F1 score\nval_precision = precision_score(val_labels, val_predictions, average='weighted')\nval_recall = recall_score(val_labels, val_predictions, average='weighted')\nval_f1 = f1_score(val_labels, val_predictions, average='weighted')\n\nprint(f\"Validation Precision: {val_precision:.2f}\")\nprint(f\"Validation Recall: {val_recall:.2f}\")\nprint(f\"Validation F1 score: {val_f1:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T18:31:11.942342Z","iopub.execute_input":"2024-06-18T18:31:11.943688Z","iopub.status.idle":"2024-06-18T18:31:34.938086Z","shell.execute_reply.started":"2024-06-18T18:31:11.943632Z","shell.execute_reply":"2024-06-18T18:31:34.936671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nimport tensorflow as tf\n\n# Load the saved model\nmodel = tf.keras.models.load_model('/kaggle/working/light_tomato.h5')\n\n# Path to the validation directory\nval_dir = '/kaggle/input/tomatoleaf/tomato/val'\n\n# Get list of disease folders\ndisease_folders = os.listdir(val_dir)\n\n# Class names\nclass_names = {\n    0: 'bacterial spot',\n    1: 'early blight',\n    2: 'late blight',\n    3: 'leaf mold',\n    4: 'Septoria',\n    5: 'spider mites',\n    6: 'target spot',\n    7: 'yellow leaf',\n    8: 'mosaic',\n    9: 'healthy'\n}\n\n# Iterate 10 times\nfor _ in range(10):\n    print(f\"Iteration {_ + 1}:\")\n    # Choose a random disease folder\n    random_folder_name = random.choice(disease_folders)\n    # Get list of images in the random disease folder\n    images = os.listdir(os.path.join(val_dir, random_folder_name))\n    # Choose a random image from the folder\n    random_image = random.choice(images)\n    # Load and preprocess the image\n    img = tf.keras.preprocessing.image.load_img(\n        os.path.join(val_dir, random_folder_name, random_image),\n        target_size=(img_height, img_width)\n    )\n    img_array = tf.keras.preprocessing.image.img_to_array(img)\n    img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n    img_array = img_array / 255.0  # Normalize\n    # Predict disease label using the model\n    predictions = model.predict(img_array)\n    predicted_label = predictions.argmax(axis=-1)[0]\n    # Update class_names dictionary if predicted_label is not in the dictionary\n    if predicted_label not in class_names:\n        class_names[predicted_label] = f'Class {predicted_label}'\n    # Get the class name from the folder name\n    actual_label = random_folder_name.split('___')[-1]\n    # Print the predicted label and actual label\n    print(f\"Predicted: {class_names[predicted_label]}, Actual: {actual_label}\")\n    print()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T18:33:50.038023Z","iopub.execute_input":"2024-06-18T18:33:50.038583Z","iopub.status.idle":"2024-06-18T18:33:51.262181Z","shell.execute_reply.started":"2024-06-18T18:33:50.038538Z","shell.execute_reply":"2024-06-18T18:33:51.260837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}